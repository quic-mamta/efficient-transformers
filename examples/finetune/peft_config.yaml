# peft config for finetuning
r: 16
lora_alpha: 64
target_modules:
  - "q_proj"
  - "v_proj"
bias: "none"
task_type: "CAUSAL_LM"
lora_dropout: 0.1
inference_mode: False

